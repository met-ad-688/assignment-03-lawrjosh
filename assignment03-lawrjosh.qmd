---
title: Assignment 03
author:
  - name: Joshua Lawrence
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-9-21'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
  docx: default
  pdf: default
date-modified: today
date-format: long
---

<!-- 1 Load the Dataset
Load the Raw Dataset:
Use Pyspark to the lightcast_data.csv file into a DataFrame: -->

```{python}
#| eval: true
#| echo: true
#| fig-align: center

import pandas as pd
import plotly.express as px
import plotly.io as pio
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id

np.random.seed(123)

pio.renderers.default = "vscode+svg+jpg"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")
df.createOrReplaceTempView("job_postings")

# Show Schema and Sample Data
print("---This is Diagnostic check, No need to print it in the final doc---")

df.printSchema() # comment this line when rendering the submission
df.show(5)
```

##  Data Prep / Cleaning

```{python}
df = df.withColumn("SALARY_FROM", col("SALARY_FROM").cast("float")) \
.withColumn("SALARY", col("SALARY").cast("float")) \
.withColumn("SALARY_TO", col("SALARY_TO").cast("float")) \
.withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float")) \
.withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("float"))

def compute_median(sdf, col_name):
    q = sdf.approxQuantile(col_name, [0.5], 0.01)
    return q[0] if q else None

median_from = compute_median(df, "SALARY_FROM")
median_to = compute_median(df, "SALARY_TO")
median_salary = compute_median(df, "SALARY")

print("Medians:", median_from, median_to, median_salary)

df = df.fillna({
  "SALARY_FROM": median_from,
  "SALARY_TO": median_to,
  "SALARY": median_salary
})

df = df.withColumn("Average_Salary", (col("SALARY_FROM") + col("SALARY_TO")) / 2)

export_cols = [
  "EDUCATION_LEVELS_NAME",
  "REMOTE_TYPE_NAME",
  "MAX_YEARS_EXPERIENCE",
  "Average_Salary",
  "SALARY",
  "EMPLOYMENT_TYPE_NAME",
  "LOT_V6_SPECIALIZED_OCCUPATION_NAME"
]
df_selected = df.select(*export_cols)

pdf = df_selected.toPandas()
pdf.to_csv("./data/lightcast_cleaned.csv", index=False)

print("Data cleaning complete. Rows retained:", len(pdf))

```

```{python}
# salary_df = df.filter(col("SALARY").isNotNull() & (col("SALARY") > 0))
# fig = px.histogram(salary_df.toPandas(), x="SALARY", nbins=50, title="Salary Distribution")
# fig.update_layout(bargap=0.1) 
# fig.show()
```
**Visualize Results**
  -Create a **box plot** where: 

## Salary Distribution by Industry and Employment Type

### Data Filtering

```{python}
pdf = df_selected.filter(df["SALARY"] > 0).select("EMPLOYMENT_TYPE_NAME", "SALARY").toPandas()
pdf = pdf.dropna()

pdf["EMPLOYMENT_TYPE_NAME"] = pdf["EMPLOYMENT_TYPE_NAME"].apply(lambda x: re.sub(r"[^\x00-\x7F]+", "", x))

median_salaries = pdf.groupby("EMPLOYMENT_TYPE_NAME")["SALARY"].median()
median_salaries.head()

sorted_employment_types = median_salaries.sort_values(ascending=False).index

pdf["EMPLOYMENT_TYPE_NAME"] = pd.Categorical(
  pdf["EMPLOYMENT_TYPE_NAME"],
  categories=sorted_employment_types,
  ordered=True
)
```

### Chart
```{python}
fig = px.box(
  pdf,
  x="EMPLOYMENT_TYPE_NAME",
  y="SALARY",
  title="Salary Distribution by Employment Type",
  color_discrete_sequence=["blue"],
  boxmode="group",
  points="all",
)
fig.update_layout(
  title=dict(
    text="Salary Distribution by Employment Type",
    font=dict(size=30, family="Arial", color="black", weight="bold")
  ),
  xaxis=dict(
    title=dict(text="Employment Type", font=dict(size=24, family="Arial", color="black", weight="bold")),
    tickangle=0,
    tickfont=dict(size=18, family="Arial", color="black", weight="bold"),
    showline=True,
    linewidth=2,
    linecolor="black",
    mirror=True,
    showgrid=False,
    categoryorder="array",
    categoryarray=sorted_employment_types.tolist()
  ),
  yaxis=dict(
    title=dict(text="Salary (K $)", font=dict(size=24, family="Arial", color="black", weight="bold")),
    tickvals=[0, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000],
    ticktext=["0", "50K", "100K", "150K", "200K", "300K", "350K", "400K", "450K", "500K"],
    tickfont=dict(size=18, family="Arial", color="black", weight="bold"),
    showline=True,
    linewidth=2,
    linecolor="black",
    mirror=True,
    showgrid=True,
    gridcolor="lightgray",
    gridwidth=0.5
  ),
  font=dict(family="Arial", size=16, color="black"),
  boxgap=0.7,
  plot_bgcolor="white",
  paper_bgcolor="white",
  showlegend=False,
  height=500,
  width=850
)
fig.show(renderer="notebook")
fig.write_html("output/Q1.html")
```

## Salary Analysis by ONET Occupation Type

### Data Filtering // Setup for Chart
```{python}
# # Step 1: Filter and select data
# bubble_df = df.filter(df["SALARY"] > 0).select("LOT_V6_SPECIALIZED_OCCUPATION_NAME", "SALARY").toPandas()
# bubble_df = bubble_df.dropna()  # Fixed: assign the result back

# print("Original data shape:", bubble_df.shape)
# print(bubble_df.head())

# # Step 2: Create grouped DataFrame with median salary and count
# grouped_bubble_df = bubble_df.groupby("LOT_V6_SPECIALIZED_OCCUPATION_NAME").agg({
#     "SALARY": ["median", "count"]
# }).reset_index()

# # Flatten column names
# grouped_bubble_df.columns = ["OCCUPATION_NAME", "MEDIAN_SALARY", "RECORD_COUNT"]

# print("\nGrouped data:")
# print(grouped_bubble_df.head())

# # Step 3: Sort by median salary (descending)
# grouped_bubble_df = grouped_bubble_df.sort_values("MEDIAN_SALARY", ascending=False).reset_index(drop=True)

# print("\nTop 10 occupations by median salary:")
# print(grouped_bubble_df.head(10))

bubble_chart_df = spark.sql("""
    SELECT 
      LOT_V6_SPECIALIZED_OCCUPATION_NAME AS ONET_NAME,
      PERCENTILE(SALARY, 0.5) AS Median_Salary,
      COUNT(*) AS Job_Postings
      FROM job_postings
      GROUP BY LOT_V6_SPECIALIZED_OCCUPATION_NAME
      ORDER BY Job_Postings DESC
      LIMIT 10
""")

bubble_chart_df_pd = bubble_chart_df.toPandas()
bubble_chart_df_pd.head()
```

### Bubble Chart
```{python}
import plotly.express as px

fig = px.scatter(
  bubble_chart_df_pd,
  x="ONET_NAME",
  y="Median_Salary",
  size="Job_Postings",
  title="Salary Analysis by LOT Occupation Type",
  labels={
    "LOT_V6_SPECIALIZED_OCCUPATION_NAME": "LOT Occupation",
    "Median_Salary": "Median Salary",
    "Job_Postings": "Number of Job Postings"
  },
  hover_name= "ONET_NAME",
  size_max=60,
  width=1000,
  height=600,
  color="Job_Postings",
  color_continuous_scale="Plasma"
)

fig.show(renderer="notebook")
fig.write_html("output/Q2.html")
```

## Salary by Education Level 
### Data Filtering / Setup
```{python}
edu_salary = df.filter(df["SALARY"] > 0).select("EDUCATION_LEVELS_NAME", "SALARY").toPandas()

edu_salary["EDUCATION_LEVELS_NAME"] = edu_salary["EDUCATION_LEVELS_NAME"].apply(lambda x: re.sub(r"\n", "", x))

unique_values = edu_salary["EDUCATION_LEVELS_NAME"].unique()
print(unique_values)


```
### Scatter Plot
```{python}

```
## Salary by Remote Work Type
### Data Filtering / Setup
```{python}

```
### Scatter Plot
```{python}

```